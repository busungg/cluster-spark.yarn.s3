FROM hadoop:latest

# add pyspark
USER root
RUN yum install -y python38-pip && \
    pip3 install pyspark && \
    pip3 install pyspark-pandas && \
    pip3 install pyarrow

# add spark user
ARG spark_passwd=spark
RUN useradd spark && \
    echo ${spark_passwd} | passwd spark --stdin && \
    usermod -aG wheel spark && \
    echo 'spark ALL=(ALL) NOPASSWD:ALL' > /etc/sudoers.d/spark

#install spark 3.4.0
USER root
WORKDIR /usr/local
RUN wget --no-check-certificate -O spark.tgz https://dlcdn.apache.org/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz
RUN tar -xvzf spark.tgz && \
    rm -f spark.tgz && \
    mv spark-3.4.0-bin-hadoop3 spark && \
    rm -f ./spark/conf/* && \
    chown -R spark:spark ./spark

WORKDIR /etc/init.d
COPY ./etc.init.d/spark ./
RUN chown root:root ./spark && \
    chmod +x ./spark && \
    chkconfig --add spark && \
    chkconfig --level 345 spark on

EXPOSE 4040 8080 8081 18080